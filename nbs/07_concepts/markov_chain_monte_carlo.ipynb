{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo (MCMC)\n",
    "> Recipes for MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from IPython.display import display, Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### Goal\n",
    "- Sample from some distribution $p(x) = \\frac{f(x)}{NC}$, but we don't know the equation for $p(x)$, only $f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why not use Accept-Reject?\n",
    "- In Accept-Reject, we:\n",
    "  - Choose some function $g(x)$ that is close to the distribution we want to sample $p(x)$\n",
    "  - Sample from $g(x)$ and accept with probability $\\frac{f(x)}{Mg(x)}$\n",
    "  - Intuitively, the ratio $\\frac{f(x)}{g(x)}$ tells us that we should prefer samples with high densities (big $f(x)$, likely to come from $p(x)$) or are rare candidates (low $g(x)$)\n",
    "- For high dimensional data, it is hard to efficiently sample from $Mg(x) > f(x)$ because $M$ tends to be very large.\n",
    "  - Large M results in low acceptance probabilties (because $\\frac{1}{M} \\propto \\text{acceptance}$)\n",
    "  - This means we need to sample a lot to get accepted samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside (math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": "$\\displaystyle \n\\begin{align}\n\\\\NC = \\int_{-\\infty}^{\\infty}f(x)dx\n\\\\\n\\\\\\text{Bayes Theorem: } P(S|A) &= \\frac{P(A|S)D(S)}{P(A)}\n\\\\&=\\frac{\\frac{f(x)}{Mg(x)} \\times g(x)}{P(A)}\n\\\\\n\\\\\\text{rearrange: } P(A) &= \\int_{-\\infty}^{\\infty}g(x)\\frac{f(x)}{Mg(x)}dx\n\\\\&=\\frac{1}{M}\\int_{-\\infty}^{\\infty}f(x)dx\n\\\\&=\\frac{NC}{M}\n\\\\\\text{rearrange: } P(S|A) &= \\frac{f(x)/M}{NC/M}\n\\\\&=\\frac{f(x)}{NC}\n\\\\&=p(x)\n\\end{align}\n$",
      "text/plain": "<IPython.core.display.Math object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse\n",
    "display(Math(r'''\n",
    "\\begin{align}\n",
    "\\\\NC = \\int_{-\\infty}^{\\infty}f(x)dx\n",
    "\\\\\n",
    "\\\\\\text{Bayes Theorem: } P(S|A) &= \\frac{P(A|S)D(S)}{P(A)}\n",
    "\\\\&=\\frac{\\frac{f(x)}{Mg(x)} \\times g(x)}{P(A)}\n",
    "\\\\\n",
    "\\\\\\text{rearrange: } P(A) &= \\int_{-\\infty}^{\\infty}g(x)\\frac{f(x)}{Mg(x)}dx\n",
    "\\\\&=\\frac{1}{M}\\int_{-\\infty}^{\\infty}f(x)dx\n",
    "\\\\&=\\frac{NC}{M}\n",
    "\\\\\\text{rearrange: } P(S|A) &= \\frac{f(x)/M}{NC/M}\n",
    "\\\\&=\\frac{f(x)}{NC}\n",
    "\\\\&=p(x)\n",
    "\\end{align}\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Solution\n",
    "- Build a markov chain that has a stationary distribution that represents $p(x)$, then sample from it.\n",
    "  - Each draw from the distribution is dependent on the previous draw (Markov Chain)\n",
    "  - Simulate draws from the markov chain (Monte Carlo)\n",
    "  - Requires drawing from the markov chain for some \"burn-in\" period before converging to $p(x)$.\n",
    "\n",
    "[![](https://mermaid.ink/img/eyJjb2RlIjoiZ3JhcGggTFJcblxuc3ViZ3JhcGggYnVybi1pblxuICAgIFhfMCAtLT4gWF8xIC0tPiBYXy4uLlxuZW5kXG5cbnN1YmdyYXBoIFwicCh4KVwiXG4gICAgWF8uLi4gLS0-IFhfQiAtLT4gWF9CKzEgLS0-IFhfQisuLi5cbmVuZCIsIm1lcm1haWQiOnt9LCJ1cGRhdGVFZGl0b3IiOmZhbHNlfQ)](https://mermaid-js.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoiZ3JhcGggTFJcblxuc3ViZ3JhcGggYnVybi1pblxuICAgIFhfMCAtLT4gWF8xIC0tPiBYXy4uLlxuZW5kXG5cbnN1YmdyYXBoIFwicCh4KVwiXG4gICAgWF8uLi4gLS0-IFhfQiAtLT4gWF9CKzEgLS0-IFhfQisuLi5cbmVuZCIsIm1lcm1haWQiOnt9LCJ1cGRhdGVFZGl0b3IiOmZhbHNlfQ)\n",
    "\n",
    "- To guarantee that the markov chain converges to $p(x)$, you need to satisfy the detailed balance condition:\n",
    "\n",
    "1. $y \\rarr x$.  $\\forall{x,y} p(x)T(y|x) = p(y)T(x|y)$  --  The probability of going $x \\rarr y$ is the same as the probability of going \n",
    "   \n",
    "2. $\\sum{p(x)T(y|x)} = \\sum{p(y)T(x|y)}$  --  Therefore the sums of those probabilities is the same\n",
    "   \n",
    "3. $pT = p$  --  Therefore we reach steady state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings\n",
    "\n",
    "The transition probability is equal to your likelihood of going from A to B times your likelihood of going from B to A.\n",
    "$$\n",
    "\\\\ \\forall{a,b}\n",
    "\\\\ p(a)T(a\\rarr b) = p(b)T(b\\rarr a)\n",
    "\\\\ \\frac{f(a)}{NC}g(b|a)A(a\\rarr b) = \\frac{f(b)}{NC}g(a|b)A(b\\rarr a)\n",
    "\\\\ \\frac{A(a\\rarr b)}{A(b\\rarr a)} = \\frac{f(b)}{f(a)} \\times \\frac{g(a|b)}{g(b|a)}\n",
    "$$\n",
    "\n",
    "Here, we note that $r_f = \\frac{f(b)}{f(a)}$ and $r_g = \\frac{g(a|b)}{g(b|a)}$\n",
    "\n",
    "For $r_fr_g <1$, $A(a\\rarr b) = r_fr_g$, and $A(b\\rarr a) = 1$\n",
    "For $r_fr_g \\ge1$, $A(a\\rarr b) = 1$, and $A(b\\rarr a) = \\frac{1}{r_fr_g}$\n",
    "\n",
    "Therefore, $A(a\\rarr b) = \\min{(1, r_fr_g)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each step, we will sample some function $g(x_{t+1}|x_t)$.  This function can be any distribution, e.g. $\\mathcal{N}(x_t, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampling\n",
    "- Useful for multidimensional sampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('fastpages': conda)",
   "name": "python388jvsc74a57bd0bab989e609fa7ae72b4d90aa019d09772e35d5f7652f4e146d62cc6a7c1dbb78"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
